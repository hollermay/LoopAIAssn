# Data Ingestion API System

A RESTful Node.js + Express API to asynchronously ingest data with batch processing, priority queueing, and rate limiting.

---

## Features

* **Two endpoints**:
  * `POST /ingest` â†’ Submit ingestion request with IDs and priority
  * `GET /status/:ingestion_id` â†’ Check status of ingestion and batches
  
* **Batch Processing**: Processes 3 IDs per batch
* **Asynchronous Execution**: Batches are queued and processed in the background
* **Priority Queue**: HIGH > MEDIUM > LOW based on FIFO + priority
* **Rate Limit**: Only 1 batch (3 IDs) processed every 5 seconds
* **Unique tracking**: Each ingestion and batch has a UUID

---

## API Endpoints

### 1. `POST /ingest`

#### Request Body:

```json
{
  "ids": [1, 2, 3, 4, 5],
  "priority": "HIGH"
}
```

* `ids` â†’ Array of integers (1 to 1e9+7)
* `priority` â†’ One of: `HIGH`, `MEDIUM`, `LOW`

#### âœ… Response:

```json
{
  "ingestion_id": "f5c3c8e0-92b2-4bfb-841e-c208660f1e7a"
}
```

---

### 2. `GET /status/:ingestion_id`

#### Response:

```json
{
  "ingestion_id": "abc123",
  "status": "triggered",
  "batches": [
    { "batch_id": "uuid-1", "ids": [1, 2, 3], "status": "completed" },
    { "batch_id": "uuid-2", "ids": [4, 5], "status": "triggered" }
  ]
}
```

#### Status Rules:

* **Batch level**: `yet_to_start`, `triggered`, `completed`
* **Ingestion level**:

  * All batches `yet_to_start` â†’ `yet_to_start`
  * Any batch `triggered` â†’ `triggered`
  * All batches `completed` â†’ `completed`

---

## Tech Stack

* Node.js
* Express.js
* UUID for tracking
* In-memory store (can be extended to Redis/PostgreSQL)

---

## Running the App Locally

```bash
git clone https://github.com/hollermay/loopaiassn.git
cd LoopAIAssn
npm install
npm run dev
```

### For production:

```bash
npm start
```

---

## ðŸ§ª Testing

Run Jest tests:

```bash
npm test
```

### Tests Include:

* Ingestion API: Valid requests, response format
* Status API: Correct status transitions
* Rate limit: Ensures one batch every 5 seconds
* Priority: Ensures higher priority batches are processed first

Screenshot of test:


![image](https://github.com/user-attachments/assets/0b27e618-d5ce-4551-badf-8f3c9422353e)

```
> PASS  test/ingestion.test.js
âœ“ processes high priority before low
âœ“ respects 5s batch rate limit
âœ“ returns correct batch statuses
```

---

## ðŸš€ Deployment on Heroku

### 1. Add a `Procfile`:

```
web: nodemon server.js
```

### 2. Push to Heroku:

```bash
heroku login
heroku create your-app-name
git push heroku master
```

### 3. Use API:

```bash
# POST
curl -X POST https://your-app-name.herokuapp.com/ingest \
-H "Content-Type: application/json" \
-d '{"ids": [1,2,3], "priority": "HIGH"}'

# GET
curl https://your-app-name.herokuapp.com/status/YOUR_INGESTION_ID
```

---

## ðŸ“Œ Design Notes
* Priorities handled using array of queues
* Batch queue processed via interval (setInterval)
* No real external API â€” mocked with delay and static response
* Easily extensible to use message queues or DB persistence
---

## And you know me well :)

**Udayan Sharma**
GitHub: [Link](https://github.com/hollermay)
Email: [Link](mailto:udayanmoudgil@email.com)
